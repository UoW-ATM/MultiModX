{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7badfa08-f90a-4a3a-9d5f-5295b666f271",
   "metadata": {},
   "source": [
    "## Analyse rail stations and airports in NUTS to get rail stations which are more 'important'\n",
    "\n",
    "Importance is defined as rail stations within the NUTS which connect with other NUTS regions. This is done by:\n",
    "\n",
    "\n",
    "<ol>\n",
    "  <p>For each rail station compute:</p>\n",
    "  <li>The NUTS (level 3) that are reachable from that station.</li>\n",
    "  <li>The number of services in the GTFS data for each NUTS reachable.</li>\n",
    "  <li>The total number of trips from that station</li>\n",
    "  <li>The distance of the station to the centroid of the population of the NUTS-3 where the rail station is located</li>\n",
    "    \n",
    "</ol>\n",
    "\n",
    "\n",
    "<ol>\n",
    "  <p>Then, for each NUTS-3 remove the rail stations ‘dominated’ by other stations. This is done by considering that a rail station is dominated by another. Station A is dominated by B, and therefore not considered if:</p>\n",
    "  <li>All the reachable NUTS from A are also reachable from B and with more services in B.</li>\n",
    "  <li>All the reachable NUTS from A are also reachable from B with the same number of services to each NUTS but B is closer to the centre of the polygon defining the NUTS-3.</li>    \n",
    "</ol>\n",
    "\n",
    "Note, if a station has a parent station that parent is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d995d40-81b6-4493-b054-042e343a6924",
   "metadata": {},
   "source": [
    "## Input data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fccb648-b9ff-4d5f-9390-9708e7778fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_level = 3\n",
    "threshold_distance_plot_between_nuts = 400\n",
    "\n",
    "nuts_data_path = '../data/EUROSTAT/NUTS_RG_01M_2021_4326.shp'\n",
    "countries = ['ES', 'DE']\n",
    "#gtfs_paths = [{'country':'ES','path':'../data/gtfs/gtfs_es/'},\n",
    "#              {'country':'DE','path':'../data/gtfs/gtfs_de/'}]\n",
    "\n",
    "gtfs_paths = [{'country':'ES','path':'../data/gtfs/gtfs_es_20220708/'},\n",
    "              {'country':'DE','path':'../data/gtfs/gtfs_de/'}]\n",
    "flight_schedules_path = '../data/flight_schedules/flight_schedule_sample.parquet'\n",
    "airports_path = '../data/airports/airport_info_static_old1409.parquet'\n",
    "census_data_path = '../data/EUROSTAT/Eurostat_Census-GRID_2021_V1-0/ESTAT_OBS-VALUE-T_2021_V1-0.tiff'\n",
    "\n",
    "output_path = '../output/data_analysis_GTFS_2022/'\n",
    "output_path_figures = '../output/data_analysis_GTFS_2022/figs/'\n",
    "generate_plots = False\n",
    "\n",
    "# Assuming the correct CRS for the data is EPSG:4326\n",
    "crs_stops = 'EPSG:4326'\n",
    "crs_airports = 'EPSG:4326'\n",
    "crs_nuts = 'EPSG:4326'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d27a0-1134-45dc-9360-27a54aa9833a",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48180d17-4c59-4657-bcd0-c6e90cd14a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "\n",
    "# Load NUTS boundary data\n",
    "nuts_data = gpd.read_file(nuts_data_path)\n",
    "\n",
    "# Load rail data\n",
    "l_stops = []\n",
    "parent_stop_dict = {}\n",
    "for gtfs in gtfs_paths:\n",
    "    stops = pd.read_csv(gtfs['path']+'stops.txt')\n",
    "    stops['stop_id'] = stops['stop_id'].apply(lambda x: gtfs['country']+str(x))\n",
    "    stops['country'] = gtfs['country']\n",
    "    # Create a dictionary of parent stations\n",
    "    parent_stop_dict_country = {row['stop_id']: f\"{gtfs['country']}{int(row['parent_station'])}\" \n",
    "                                for index, row in stops[~stops.parent_station.isnull()][['stop_id', 'parent_station']].iterrows()}\n",
    "\n",
    "    parent_stop_dict = {**parent_stop_dict, **parent_stop_dict_country}\n",
    "    \n",
    "    # Drop stops that have a parent\n",
    "    stops = stops[stops.parent_station.isnull()]\n",
    "\n",
    "    l_stops += [stops]\n",
    "\n",
    "stops = pd.concat(l_stops).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Load airports data\n",
    "airports = pd.read_parquet(airports_path)[['icao_id','lat','lon']]\n",
    "\n",
    "\n",
    "# Prepare the data\n",
    "\n",
    "# Create Point objects from coordinates for train stations\n",
    "stops['geometry'] = stops.apply(lambda x: Point(x.stop_lon, x.stop_lat), axis=1)\n",
    "\n",
    "# Create Point objects from coordinates for airports\n",
    "airports['geometry'] = airports.apply(lambda x: Point(x.lon, x.lat), axis=1)\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "stops = gpd.GeoDataFrame(stops, geometry='geometry')\n",
    "airports = gpd.GeoDataFrame(airports, geometry='geometry')\n",
    "\n",
    "# Add CRS\n",
    "stops.crs = crs_stops\n",
    "airports.crs = crs_airports\n",
    "nuts_data.crs = crs_nuts\n",
    "\n",
    "# Re-project to a projected CRS (e.g., EPSG:3857)\n",
    "projected_crs = 'EPSG:3857'\n",
    "stops_proj = stops.to_crs(projected_crs)\n",
    "\n",
    "# Buffer the points slightly (e.g., by 10 meters) -- due to Dagebüll Mole rail station in edge of NUTS\n",
    "stops_proj['geometry'] = stops_proj['geometry'].buffer(10)\n",
    "\n",
    "# Re-project back to the original geographic CRS\n",
    "stops = stops_proj.to_crs(crs_stops)\n",
    "\n",
    "# Perform spatial join\n",
    "joined_rail = gpd.sjoin(stops, nuts_data, predicate='intersects', how='left') \n",
    "joined_airports = gpd.sjoin(airports, nuts_data, predicate='within', how='left')\n",
    "\n",
    "# Group the rail stations by NUTS region\n",
    "grouped_rail = joined_rail.groupby('NUTS_ID')[['stop_id', 'stop_name']].apply(lambda x: list(zip(x['stop_id'], x['stop_name']))).reset_index()\n",
    "grouped_rail.columns = ['NUTS_ID', 'rail_stations']\n",
    "\n",
    "grouped_airports = joined_airports.groupby('NUTS_ID')[['icao_id']].apply(lambda x: list(x['icao_id'])).reset_index()\n",
    "grouped_airports.columns = ['NUTS_ID', 'airports']\n",
    "\n",
    "\n",
    "# Merge the grouped data back to nuts_data\n",
    "nuts_data = nuts_data.merge(grouped_rail, on='NUTS_ID', how='left')\n",
    "nuts_data = nuts_data.merge(grouped_airports, on='NUTS_ID', how='left')\n",
    "\n",
    "nuts_data['num_rail_stations'] = nuts_data['rail_stations'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "nuts_data['num_airports'] = nuts_data['airports'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Create a dictionary of nuts for the different rail stations and airports\n",
    "dict_stations_nuts = {}\n",
    "for i, row in nuts_data[(nuts_data['rail_stations'].notna()) & (nuts_data['LEVL_CODE']==nuts_level)].iterrows():\n",
    "    for s in row['rail_stations']:\n",
    "        dict_stations_nuts[s[0]] = row['NUTS_ID']\n",
    "\n",
    "dict_airports_nuts = {}\n",
    "for i, row in nuts_data[(nuts_data['airports'].notna()) & (nuts_data['LEVL_CODE']==nuts_level)].iterrows():\n",
    "    for s in row['airports']:\n",
    "        dict_airports_nuts[s] = row['NUTS_ID']\n",
    "\n",
    "\n",
    "# Add the nuts to the rail stops and the airports\n",
    "stops['nuts'] = stops['stop_id'].apply(lambda x: dict_stations_nuts.get(x))\n",
    "airports['nuts'] = airports['icao_id'].apply(lambda x: dict_airports_nuts.get(x))\n",
    "\n",
    "# Merge nuts into rail stops\n",
    "stops = stops.merge(nuts_data[['NUTS_ID', 'geometry']], how='left', left_on=['nuts'], right_on=['NUTS_ID'], suffixes=('','_nuts'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7925eba4-1b82-4a85-891c-fb61a3eebae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw results (no filtering)\n",
    "for c in countries:\n",
    "    nuts_data[(nuts_data.CNTR_CODE==c) & (nuts_data.LEVL_CODE==3)][['NUTS_ID','LEVL_CODE','NAME_LATN','num_rail_stations','num_airports','airports','rail_stations']].to_csv(output_path+'nuts3_'+c+'_no_filtering.csv', index=False)\n",
    "    nuts_data[(nuts_data.CNTR_CODE==c) & (nuts_data.LEVL_CODE==2)][['NUTS_ID','LEVL_CODE','NAME_LATN','num_rail_stations','num_airports','airports','rail_stations']].to_csv(output_path+'nuts2_'+c+'_no_filtering.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d447287-f35d-417c-92fd-b542b6179c51",
   "metadata": {},
   "source": [
    "### Filter rail stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84018bb6-15ee-47c8-9c1f-eeab0a75137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute centroid of the population for each nuts\n",
    "import fiona\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.warp import transform_geom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio.warp\n",
    "import pyproj\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "dict_centroid_pop = {}\n",
    "\n",
    "# Read the NUTS region geometry\n",
    "for i, row in nuts_data[(nuts_data.CNTR_CODE.isin(countries)) & (nuts_data.LEVL_CODE==nuts_level)].iterrows():\n",
    "    nuts_interest_id = row.NUTS_ID\n",
    "    nuts_interest_name = row.NAME_LATN\n",
    "    nuts_interest = row.geometry\n",
    "      \n",
    "    # Read the population distribution raster\n",
    "    with rasterio.open(census_data_path) as src:\n",
    "        # Reproject the NUTS region geometry to match the CRS of the raster\n",
    "        census_crs = src.crs\n",
    "        if crs_nuts != census_crs:\n",
    "            nut_region = transform_geom(\n",
    "                crs_nuts, census_crs, nuts_interest, precision=6)\n",
    "        # Clip the raster by the NUTS boundary\n",
    "        out_image, out_transform = mask(src, [nut_region], crop=True)\n",
    "        out_meta = src.meta.copy()\n",
    "\n",
    "\n",
    "    # Summarize population within the NUTS region\n",
    "    total_population = out_image.sum()\n",
    "\n",
    "    # Compute the weighted sum of the population within each pixel\n",
    "    weighted_population = np.sum(out_image)\n",
    "    \n",
    "    # Create arrays of indices along the x and y axes\n",
    "    x_indices = np.arange(out_image.shape[2])\n",
    "    y_indices = np.arange(out_image.shape[1])\n",
    "    \n",
    "    # Compute the weighted centroid\n",
    "    weighted_centroid_x = (np.sum(out_image * x_indices) / weighted_population) / out_image.shape[2]\n",
    "    weighted_centroid_y = (np.sum(out_image * y_indices[:, np.newaxis]) / weighted_population) / out_image.shape[1]\n",
    "    \n",
    "    # Get the affine transformation matrix\n",
    "    transform_matrix = out_transform\n",
    "    \n",
    "    # Calculate the geographic coordinates of the centroid\n",
    "    centroid_x_geo = transform_matrix[2] + weighted_centroid_x * out_image.shape[2] * transform_matrix[0] \n",
    "    centroid_y_geo = transform_matrix[5] + weighted_centroid_y * out_image.shape[1] * transform_matrix[4] \n",
    "    \n",
    "    # Transform the centroid coordinates to the CRS of the NUTS region\n",
    "    transformer = pyproj.Transformer.from_crs(census_crs, crs_nuts, always_xy=True)\n",
    "    centroid_x_nut, centroid_y_nut =  transformer.transform(centroid_x_geo, centroid_y_geo)\n",
    "\n",
    "    dict_centroid_pop[nuts_interest_id] = (centroid_x_nut, centroid_y_nut)\n",
    "\n",
    "    if generate_plots:\n",
    "        \n",
    "        # Define the target CRS (e.g., EPSG:3035)\n",
    "        target_crs = crs_nuts \n",
    "        \n",
    "        # Create an empty array for the destination\n",
    "        out_image_reprojected = np.empty((out_image.shape[0], out_image.shape[1], out_image.shape[2]), dtype=out_image.dtype)\n",
    "        \n",
    "        # Reproject the image to the target CRS\n",
    "        out_image_reprojected, out_transform_reprojected = rasterio.warp.reproject(\n",
    "            out_image,\n",
    "            out_image_reprojected,\n",
    "            src_crs=census_crs, \n",
    "            dst_crs=target_crs, \n",
    "            src_transform=out_transform, \n",
    "            src_nodata=None, \n",
    "            dst_width=out_image.shape[2], \n",
    "            dst_height=out_image.shape[1], \n",
    "            dst_nodata=None, \n",
    "            resampling=rasterio.enums.Resampling.nearest)\n",
    "        \n",
    "        \n",
    "        # Calculate the extent of the reprojected image\n",
    "        x_min = out_transform_reprojected[2]\n",
    "        y_min = out_transform_reprojected[5] + out_transform_reprojected[4] * out_image.shape[1]\n",
    "        x_max = out_transform_reprojected[2] + out_transform_reprojected[0] * out_image.shape[2]\n",
    "        y_max = out_transform_reprojected[5]\n",
    "        \n",
    "        # Visualize the population distribution in the target CRS\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        plt.imshow(np.squeeze(out_image_reprojected), cmap='viridis', extent=[x_min, x_max, y_min, y_max],alpha=0.5)\n",
    "        # Plot the NUTS geometry perimeter\n",
    "        if isinstance(nuts_interest, MultiPolygon):\n",
    "            for geom in nuts_interest.geoms:\n",
    "                x, y = geom.exterior.xy\n",
    "                ax.plot(x, y, color='blue', label='NUTS Perimeter')\n",
    "        elif isinstance(nuts_interest, Polygon):\n",
    "            x, y = nuts_interest.exterior.xy\n",
    "            ax.plot(x, y, color='blue', label='NUTS Perimeter')\n",
    "        \n",
    "        ax.scatter(centroid_x_nut, centroid_y_nut, color='red', marker='x', s=100, label='Weighted Centroid')\n",
    "        \n",
    "        plt.colorbar(label='Population')\n",
    "        plt.title('Population Distribution '+nuts_interest_name+' '+str(total_population)+' Pop')\n",
    "        plt.xlabel('X Coordinate (Projected)')\n",
    "        plt.ylabel('Y Coordinate (Projected)')\n",
    "        plt.savefig(output_path_figures+str(nuts_level)+'_'+nuts_interest_id+\"_\"+nuts_interest_name.replace('/', '_')+\".png\")\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396146ce-ce5b-45f8-ad7d-24497753a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    # Convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    radius_earth = 6371  # Radius of the Earth in kilometers\n",
    "    distance = radius_earth * c\n",
    "\n",
    "    return distance\n",
    "  \n",
    "stops['centroid_nuts'] = stops['nuts'].apply(lambda x: dict_centroid_pop.get(x))\n",
    "stops['distance_nuts_pop_centr'] = stops.apply(lambda x: haversine(x.centroid_nuts[0], x.centroid_nuts[1],\n",
    "                                                                   x.stop_lon, x.stop_lat) if x.centroid_nuts is not None else 0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d6cb9-bc0e-4c4c-bc1c-6f87eaaa4313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for each station which regions can be reached based on the stops_times\n",
    "l_stops = []\n",
    "for gtfs in gtfs_paths:\n",
    "    stop_times = pd.read_csv(gtfs['path']+'stop_times.txt')\n",
    "    stop_times['stop_id'] = stop_times['stop_id'].apply(lambda x: gtfs['country']+str(x))\n",
    "    stop_times['stop_id'] = stop_times['stop_id'].apply(lambda x: parent_stop_dict.get(x,x))\n",
    "    stop_times['nuts'] = stop_times['stop_id'].apply(lambda x: dict_stations_nuts[x])\n",
    "    l_stops += [stop_times]\n",
    "\n",
    "stop_times = pd.concat(l_stops).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Function to get unique NUTS regions after each stop within a trip\n",
    "def get_nuts_for_stop(group):\n",
    "    nuts_for_stop = {}\n",
    "    for i, row in group.iterrows():\n",
    "        # Get the NUTS3 regions after the current stop\n",
    "        nuts_after_stop = group.loc[i:, 'nuts'].unique()\n",
    "        nuts_for_stop[row['stop_id']] = set(nuts_after_stop)\n",
    "    return nuts_for_stop\n",
    "\n",
    "# Group by trip_id and apply the get_nuts_for_stop function\n",
    "# It has for each trip which NUTs can be reached from which stop\n",
    "nuts_for_stops = stop_times.groupby('trip_id').apply(get_nuts_for_stop).reset_index()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f79bd-f7f3-4565-a4d9-a10b4d172f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute nuts reachable from each station, number of trips per nuts\n",
    "dict_nuts_reachable_station = {}\n",
    "dict_number_trips_station = {}\n",
    "dict_number_trips_station_to_nuts = {}\n",
    "nuts_considered = set()\n",
    "\n",
    "for dict_s_nuts in nuts_for_stops[0]:\n",
    "    for station, nuts_reachable in dict_s_nuts.items():\n",
    "        nuts_considered = nuts_considered.union(nuts_reachable)\n",
    "        if station not in dict_nuts_reachable_station.keys():\n",
    "            dict_nuts_reachable_station[station] = set()\n",
    "        if station not in dict_number_trips_station.keys():\n",
    "            dict_number_trips_station[station] = 0\n",
    "        if station not in dict_number_trips_station_to_nuts.keys():\n",
    "            dict_number_trips_station_to_nuts[station] = {}\n",
    "            \n",
    "        dict_nuts_reachable_station[station] = dict_nuts_reachable_station[station].union(nuts_reachable)\n",
    "        dict_number_trips_station[station] += 1\n",
    "        \n",
    "        for n in nuts_reachable:\n",
    "            if n not in dict_number_trips_station_to_nuts[station].keys():\n",
    "                dict_number_trips_station_to_nuts[station][n] = 0\n",
    "            dict_number_trips_station_to_nuts[station][n] += 1\n",
    "\n",
    "dict_distance_centroid_pop_stop = dict(zip(stops['stop_id'], stops['distance_nuts_pop_centr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f1f17f-2288-46e1-be11-5e3f082c8bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtering\n",
    "\n",
    "# Pareto stations for nuts\n",
    "stops['nuts_reachable'] = stops['stop_id'].apply(lambda x: dict_nuts_reachable_station.get(x))\n",
    "stops['n_nuts_reachable'] = stops['nuts_reachable'].apply(lambda x: 0 if x is None else len(x))\n",
    "stops['n_trips'] = stops['stop_id'].apply(lambda x: dict_number_trips_station.get(x, 0))\n",
    "stops['n_trips_nuts'] = stops['stop_id'].apply(lambda x: dict_number_trips_station_to_nuts.get(x))\n",
    "\n",
    "def is_dominated(df_stations, i):\n",
    "    current_stop_id = df_stations['stop_id'].loc[i]\n",
    "    current_nuts_reachable = df_stations['nuts_reachable'].loc[i]\n",
    "    current_n_trips = df_stations['n_trips'].loc[i]\n",
    "    if current_n_trips == 0:\n",
    "        return True\n",
    "    current_n_trips_nuts = df_stations['n_trips_nuts'].loc[i]\n",
    "    current_dist_centre_nuts = df_stations['distance_nuts_pop_centr'].loc[i]\n",
    "\n",
    "    for ic in df_stations.index:\n",
    "        if ic != i:\n",
    "            other_nuts_reachable = df_stations['nuts_reachable'].loc[ic]\n",
    "            other_n_trips = df_stations['n_trips'].loc[ic]\n",
    "            other_n_trips_nuts = df_stations['n_trips_nuts'].loc[ic]\n",
    "            other_dist_centre_nuts = df_stations['distance_nuts_pop_centr'].loc[ic]\n",
    "            if other_n_trips > 0:\n",
    "\n",
    "                if current_nuts_reachable <= other_nuts_reachable:\n",
    "                    # Can reach the same nuts as the other\n",
    "                    current_trips_nuts = list(current_n_trips_nuts.keys())\n",
    "                    i_n = 0\n",
    "                    dominated = True\n",
    "                    while (i_n < len(current_trips_nuts)) and dominated:\n",
    "                        nuts_looking = current_trips_nuts[i_n]\n",
    "                        if current_n_trips_nuts[nuts_looking] > other_n_trips_nuts[nuts_looking]:\n",
    "                            dominated = False\n",
    "                        i_n += 1\n",
    "    \n",
    "                    if dominated:   \n",
    "                        # If we are here we checked all the nuts and we don't have fewer options\n",
    "                        # we could have the same for all of them\n",
    "                        all_equal = True\n",
    "                        i_n = 0\n",
    "                        while (i_n < len(current_trips_nuts)) and all_equal:\n",
    "                            n = current_trips_nuts[i_n]\n",
    "                            if current_n_trips_nuts[n] != other_n_trips_nuts[n]:\n",
    "                                all_equal = False\n",
    "                            i_n += 1\n",
    "        \n",
    "                        if not all_equal or current_dist_centre_nuts > other_dist_centre_nuts:\n",
    "                            # If all the same check the distance w.r.t. centre nuts to keep only one\n",
    "                            return True\n",
    "                \n",
    "    return False\n",
    "    \n",
    "    \n",
    "    \n",
    "dict_rail_stations_nuts = {}\n",
    "for n in nuts_considered: #[x for x in nuts_considered if x.startswith('DE')]: #nuts_considered:\n",
    "    stops_n = stops[stops.nuts==n].copy()\n",
    "    stops_keep = []\n",
    "    for stop_index in stops_n.index:\n",
    "        if not is_dominated(stops_n, stop_index):\n",
    "            stops_keep += [stops_n.loc[stop_index].stop_id]\n",
    "        \n",
    "    dict_rail_stations_nuts[n] = stops_keep\n",
    "    \n",
    "\n",
    "\n",
    "stations_kept = []\n",
    "for s in dict_rail_stations_nuts.values():\n",
    "    stations_kept += s\n",
    "\n",
    "len(stations_kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47baad7a-9135-442e-8060-369f858cb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results filtered\n",
    "stops_kept = stops[stops.stop_id.isin(stations_kept)]\n",
    "dict_aggreaged_rail = {}\n",
    "for c in stops_kept.country.drop_duplicates():\n",
    "    stops_kept[stops_kept.country==c]\n",
    "    \n",
    "    # Merge dataframes\n",
    "    merged_df = stops_kept[stops_kept.country==c][['stop_id', 'stop_name', 'NUTS_ID']].merge(nuts_data[['NUTS_ID','NAME_LATN','LEVL_CODE']], on='NUTS_ID', how='left')\n",
    "    \n",
    "    # Group by NUTS_ID and aggregate data\n",
    "    \n",
    "    # Group by NUTS_ID and aggregate data\n",
    "    aggregated_df = merged_df.groupby(['NUTS_ID', 'NAME_LATN', 'LEVL_CODE']).agg(\n",
    "        num_rail_stations=('stop_id', 'nunique'),  # Count the number of unique rail stations\n",
    "        rail_stations=('stop_id', lambda x: list(zip(x, merged_df.loc[merged_df['stop_id'].isin(x), 'stop_name'])))  # Construct the list of rail stations\n",
    "    ).reset_index()   \n",
    "\n",
    "    dict_aggreaged_rail[c] =  aggregated_df[['NUTS_ID', 'LEVL_CODE', 'NAME_LATN', 'LEVL_CODE', 'num_rail_stations', 'rail_stations']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f81322d-f30c-442a-99e9-da3b61ad9318",
   "metadata": {},
   "source": [
    "### Filter airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c27860e-560a-4f02-9ac5-aa46ce68d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read flight schedules for a given day\n",
    "df_fs = pd.read_parquet(flight_schedules_path)\n",
    "\n",
    "# Keep airports from which flights depart and arrive\n",
    "airports_w_flights = set(df_fs['origin']).union(df_fs['destination'])\n",
    "\n",
    "\n",
    "filtered_airports = airports[airports.icao_id.isin(airports_w_flights)]\n",
    "\n",
    "nuts_data['aiports_filtered'] = None\n",
    "i_w_a = ~nuts_data['airports'].isnull()\n",
    "\n",
    "nuts_data.loc[i_w_a, 'aiports_filtered'] = nuts_data.loc[i_w_a]['airports'].apply(lambda x: list(set(x).intersection(airports_w_flights)))\n",
    "\n",
    "nuts_data['num_airports_filtered'] = nuts_data['aiports_filtered'].apply(lambda x: len(x) if x is not None else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7187a64f-235c-4db2-858b-31f8c8a14cf0",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35eb0e8-8f51-4faa-af2c-bc586e8329bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge back airports and rail results\n",
    "lraildf = []\n",
    "for r in dict_aggreaged_rail.values():\n",
    "    lraildf += [r]\n",
    "\n",
    "rail_df_filtered = pd.concat(lraildf)\n",
    "\n",
    "df = nuts_data[(nuts_data.CNTR_CODE.isin(countries)) & (nuts_data.LEVL_CODE==nuts_level)][['NUTS_ID','CNTR_CODE','LEVL_CODE','NAME_LATN','num_airports_filtered','aiports_filtered']].copy()\n",
    "\n",
    "\n",
    "df = df.merge(rail_df_filtered[['NUTS_ID','num_rail_stations','rail_stations']], how='left', on='NUTS_ID')\n",
    "df.loc[df.num_rail_stations.isnull(),'num_rail_stations'] = 0\n",
    "df = df.rename({'aiports_filtered': 'airports', 'num_airports_filtered': 'num_airports'}, axis=1)\n",
    "for c in countries:\n",
    "    df[df.CNTR_CODE==c][['NUTS_ID','LEVL_CODE','NAME_LATN','num_rail_stations','num_airports',\n",
    "                        'airports','rail_stations']].to_csv(output_path+'nuts'+str(nuts_level)+'_'+c+'_filtered.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e9b532-8d85-48d6-836d-041ce94519e5",
   "metadata": {},
   "source": [
    "### Create html for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a997373-5bcf-40f4-aee5-7c178167247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "# Sample grouped data for airports\n",
    "df_f_g = df_fs.groupby('origin').count().reset_index()\n",
    "dict_departures_airports = dict(zip(df_f_g['origin'], df_f_g['destination']))\n",
    "df_f_g = df_fs.groupby('destination').count().reset_index()\n",
    "dict_arrivals_airports = dict(zip(df_f_g['destination'], df_f_g['origin']))\n",
    "\n",
    "your_latitude = 47.24\n",
    "your_longitude = 3.28\n",
    "\n",
    "# Create a map centered at a specific location\n",
    "map_center = [your_latitude, your_longitude]  # Specify the center of the map\n",
    "m = folium.Map(location=map_center, zoom_start=5)  # Adjust zoom level as needed\n",
    "\n",
    "max_circle = 20\n",
    "stops_kept = stops[stops.stop_id.isin(stations_kept)]\n",
    "dict_factor = (max_circle / stops_kept.groupby('country').n_nuts_reachable.max()).to_dict()\n",
    "\n",
    "# Create feature group for circle markers\n",
    "dict_cmgr = {}\n",
    "for c in stops_kept.country.drop_duplicates():\n",
    "    dict_cmgr[c] = folium.FeatureGroup(name='Rail stations ' + c)\n",
    "\n",
    "# Add NUTS regions with translucent filling\n",
    "nuts_feature_group = folium.FeatureGroup(name='NUTS Regions')\n",
    "for idx, row in nuts_data[(nuts_data.LEVL_CODE==nuts_level) & (nuts_data.CNTR_CODE.isin(countries))].iterrows():\n",
    "    folium.GeoJson(\n",
    "        data=row.geometry.__geo_interface__,\n",
    "        style_function=lambda x: {'fillColor': 'orange', 'color': 'orange', 'fillOpacity': 0.2, 'weight': 3},\n",
    "        tooltip=f\"NUTS ID: {row['NUTS_ID']}\"\n",
    "    ).add_to(nuts_feature_group)\n",
    "\n",
    "# Add the NUTS regions to the map\n",
    "nuts_feature_group.add_to(m)\n",
    "\n",
    "\n",
    "# Add circles for each stop with size proportional to NUTS reachable\n",
    "for index, row in stops_kept.iterrows():\n",
    "    stop_id = row['stop_id']\n",
    "    stop_name = row['stop_name']\n",
    "    n_nuts_reachable = row['n_nuts_reachable']\n",
    "    n_trips = row['n_trips']\n",
    "    lat = row['stop_lat']\n",
    "    lon = row['stop_lon']\n",
    "    nuts_id = row['NUTS_ID']\n",
    "    country = row['country']\n",
    "    \n",
    "    # Calculate circle radius based on NUTS reachable\n",
    "    radius = n_nuts_reachable * dict_factor[row['country']]  # Adjust multiplier as needed\n",
    "    \n",
    "    # Add circle marker to the map\n",
    "    folium.CircleMarker(\n",
    "        location=[lat, lon],\n",
    "        radius=radius,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='blue',\n",
    "        fill_opacity=0.5,\n",
    "        popup=f\"{stop_name}<br>Nuts reachable: {n_nuts_reachable}<br>Num trips: {n_trips}<br>NUTS: {nuts_id}\",\n",
    "    ).add_to(dict_cmgr[country])\n",
    "\n",
    "# Add feature group to the map\n",
    "for c in dict_cmgr.values():\n",
    "    c.add_to(m)\n",
    "\n",
    "# Add airports\n",
    "dict_cmga = {}\n",
    "for c in countries:\n",
    "    airports_c = set([item for sublist in list(df[(df.CNTR_CODE == c) & (df.airports.notnull())]['airports']) for item in sublist])\n",
    "    ac = airports[airports.icao_id.isin(airports_c)]\n",
    "    if len(ac) > 0:\n",
    "        dict_cmga[c] = folium.FeatureGroup(name='Airports ' + c)\n",
    "        \n",
    "        for index, row in ac.iterrows():\n",
    "            lat = row['lat']\n",
    "            lon = row['lon']\n",
    "            icao = row['icao_id']\n",
    "            departures = dict_departures_airports.get(icao, 0)\n",
    "            arrivals = dict_arrivals_airports.get(icao, 0)\n",
    "            n_flights = departures + arrivals\n",
    "            \n",
    "            # Calculate circle radius based on PageRank centrality\n",
    "            radius = max(4, n_flights * 0.01)\n",
    "            \n",
    "            # Add circle marker to the map\n",
    "            folium.CircleMarker(\n",
    "                location=[lat, lon],\n",
    "                radius=radius,\n",
    "                color='red',\n",
    "                fill=True,\n",
    "                fill_color='red',\n",
    "                fill_opacity=0.5,\n",
    "                popup=f\"{icao}<br>Departures: {departures}<br>Arrivals: {arrivals}\",\n",
    "            ).add_to(dict_cmga[c])\n",
    "\n",
    "for c in dict_cmga.values():\n",
    "    c.add_to(m)\n",
    "\n",
    "\n",
    "\n",
    "# Add layer control with custom buttons\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "m.save(output_path+'filtered_nuts_'+str(nuts_level)+'_with_nuts_'+'_'.join(countries)+'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c9aa0-4a6b-45a0-b620-8a08cf0a0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_distance_matrix_nuts = {}\n",
    "\n",
    "for c in countries:\n",
    "    nuts_ids_c = nuts_data[(nuts_data.CNTR_CODE==c) & (nuts_data.LEVL_CODE==nuts_level)]['NUTS_ID']\n",
    "    \n",
    "    distance_matrix = np.zeros((len(nuts_ids_c), len(nuts_ids_c)))\n",
    "    \n",
    "    # Compute distances\n",
    "    for i, nuts_id1 in enumerate(nuts_ids_c):\n",
    "        for j, nuts_id2 in enumerate(nuts_ids_c):\n",
    "            if i != j:\n",
    "                lon1, lat1 = dict_centroid_pop[nuts_id1]\n",
    "                lon2, lat2 = dict_centroid_pop[nuts_id2]\n",
    "                distance_matrix[i, j] = haversine(lon1, lat1, lon2, lat2)\n",
    "                if nuts_id2 == 'DEF0C':\n",
    "                    pass #rint(\"HERE\")\n",
    "    \n",
    "    # Convert the distance matrix to a DataFrame for easier handling\n",
    "    dict_distance_matrix_nuts[c] = pd.DataFrame(distance_matrix, index=nuts_ids_c, columns=nuts_ids_c).sort_index(axis=0).sort_index(axis=1)\n",
    "\n",
    "\n",
    "# Plot the heatmap of distances\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for c in countries:\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(dict_distance_matrix_nuts[c], fmt=\".2f\", cmap=\"YlGnBu\")\n",
    "    plt.title(\"Distance Matrix Heatmap \"+c)\n",
    "    plt.savefig(output_path_figures+c+\"_\"+str(nuts_level)+\"_distance_pop_centroid_matrix.png\")\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "for c in countries:\n",
    "    vmin_value = threshold_distance_plot_between_nuts\n",
    "    vmax_value = threshold_distance_plot_between_nuts+0.001\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(dict_distance_matrix_nuts[c], fmt=\".2f\", cmap=\"YlGnBu\", vmin=vmin_value, vmax=vmax_value)\n",
    "    plt.title(\"Distance Matrix Heatmap \"+c+\" threshold \"+str(threshold_distance_plot_between_nuts)+\"km\")\n",
    "    plt.savefig(output_path_figures+c+\"_\"+str(nuts_level)+\"_distance_pop_centroid_matrix_threshold.png\")\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "# Save distance matrices\n",
    "for c in countries:\n",
    "    dict_distance_matrix_nuts[c].to_csv(output_path+'nuts'+str(nuts_level)+'_'+c+'_distance_pop_centroid_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2bea9-44f0-4e33-9744-49636a1898fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensky",
   "language": "python",
   "name": "opensky"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
