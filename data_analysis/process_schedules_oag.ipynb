{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e80945-929f-452c-9d07-29ff675a178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_schedules_oag = '../data/oag_schedules/OAG_global_6SEP2019.csv'\n",
    "f_airports = '../data/airports/airports_coordinates_updated.csv'\n",
    "f_airports_iata_icao = '../data/airports/IATA_ICAO_Airport_codes_v0.3.csv'\n",
    "\n",
    "countries_interest = ['ES'] #, 'DE']\n",
    "#airports_intesrest = ['LHR', 'CDG', 'FRA', 'MUC', 'AMS', 'LIS', 'FCO', 'ZRH']\n",
    "airports_intesrest = []\n",
    "general_ac_remove = ['TRN', 'BUS', 'LCH', 'AWH'] # Trains, Bus, Launch (boat), AWH (helicopter)\n",
    "specific_ac_remove = ['RFS'] # RFS - Road Feeder Service (Truck)\n",
    "\n",
    "f_schedules_output = '../data/flight_schedules_oag_es.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1bf40-495b-4bc3-82ea-8c9891a5d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_schedules_oag = pd.read_csv(f_schedules_oag)\n",
    "df_airports = pd.read_csv(f_airports)\n",
    "df_airports_iata_icao = pd.read_csv(f_airports_iata_icao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85878527-cc6d-488f-9750-fc1ea91fb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_schedules_oag[df_schedules_oag.DepAirport=='MAD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3281d2f-25f4-4cab-8a4a-9d3e7bb0db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that airport icao-iata don't have duplicate IATA code, as otherwise when doing the merge the flights get duplicated...\n",
    "df_airports_iata_icao[['IATA']].drop_duplicates()\n",
    "df_airports_iata_icao[df_airports_iata_icao.duplicated(subset=['IATA'], keep=False)]['IATA'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389cf3ee-d559-4bbe-90a4-eca187c1d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove codeshares because airline share is not null (i.e., another airline is doing the flight)\n",
    "# The comment above was the idea I had, but it seems that two flights can have both ShAirlDes and one of them\n",
    "# be operated, (see example of MAD-LIS flights). So dont' do this. Instead see code later for codeshares\n",
    "# There can still be codeshares, see later\n",
    "print(len(df_schedules_oag[df_schedules_oag.DepAirport=='MAD']))\n",
    "print(len(df_schedules_oag[df_schedules_oag.DepAirport=='BCN']))\n",
    "#df_schedules_oag = df_schedules_oag[df_schedules_oag.ShAirlDes.isnull()].copy()\n",
    "print(len(df_schedules_oag[df_schedules_oag.DepAirport=='MAD']))\n",
    "print(len(df_schedules_oag[df_schedules_oag.DepAirport=='BCN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33f9be-460b-46dc-8ec0-1ef73af09fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vdf_schedules_oag[((df_schedules_oag.Carrier1=='QR') | (df_schedules_oag.Carrier1=='VY') | (df_schedules_oag.Carrier1=='IB')) & (df_schedules_oag.DepAirport=='PMI') & ((df_schedules_oag.ArrAirport=='BCN'))].to_csv('../data/oag_schedules/test_code_share.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0154f55f-7161-4de8-a9b0-dcba2a80a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_schedules_oag_grouped = df_schedules_oag.groupby(['DepAirport', 'ArrAirport', 'LocalDepTime', 'LocalArrTime'])\n",
    "# filtered_df = df_schedules_oag_grouped.filter(lambda x: len(x) > 1)\n",
    "# filtered_df.to_csv('../data/oag_schedules/same_de_arr_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5946c4-0763-41c1-abdd-a03fc781e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique service ids for the flights\n",
    "def make_unique_service_ids(df, column):\n",
    "    seen = {}\n",
    "    unique_ids = []\n",
    "    \n",
    "    for service_id in df[column]:\n",
    "        if service_id in seen:\n",
    "            seen[service_id] += 1\n",
    "            unique_id = f\"{service_id}_{seen[service_id]}\"\n",
    "        else:\n",
    "            seen[service_id] = 0\n",
    "            unique_id = service_id\n",
    "        \n",
    "        unique_ids.append(unique_id)\n",
    "    \n",
    "    return unique_ids\n",
    "\n",
    "\n",
    "df_schedules_oag['service_id'] = df_schedules_oag['Carrier1'] + '_' + df_schedules_oag['FlightNo1'].astype(str)\n",
    "\n",
    "df_schedules_oag['service_id'] = make_unique_service_ids(df_schedules_oag, 'service_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8b55a-13f8-474b-9f15-3e1b82a4c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_schedules_oag[df_schedules_oag['DepAirport']=='MAD']))\n",
    "print(len(df_schedules_oag[df_schedules_oag['DepAirport']=='BCN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cbc4b7-5c2f-42e1-9b25-8b8e94fee707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter operations that we could be interested\n",
    "\n",
    "# Filter data to keep one of interest\n",
    "print(len(df_schedules_oag))\n",
    "df_s = df_schedules_oag[df_schedules_oag.ArrIATACtry.isin(countries_interest) | \n",
    "                        df_schedules_oag.DepIATACtry.isin(countries_interest) |\n",
    "                        df_schedules_oag.DepAirport.isin(airports_intesrest) |\n",
    "                        df_schedules_oag.ArrAirport.isin(airports_intesrest)].copy()\n",
    "print(len(df_s))\n",
    "print(len(df_s[df_s['DepAirport']=='MAD']))\n",
    "print(len(df_s[df_s['DepAirport']=='BCN']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056d5ad-cd17-4a21-8516-d46a2eadb09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_s))\n",
    "# Further filter things that are not flights or we don't care\n",
    "df_s = df_s[~df_s.SpecificAcft.isin(specific_ac_remove) &\n",
    "            ~df_s.GeneralAcft.isin(general_ac_remove)]\n",
    "print(len(df_s))\n",
    "\n",
    "# Remove circular flights\n",
    "df_s = df_s[df_s.DepAirport!=df_s.ArrAirport]\n",
    "print(len(df_s))\n",
    "\n",
    "\n",
    "df_s = df_s.copy().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16913f49-6e8e-4998-ab4b-08e69d9e0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ICAO origin and destination\n",
    "df_s = df_s.merge(df_airports_iata_icao[['ICAO', 'IATA']], left_on='DepAirport', right_on='IATA', how='left').rename(columns={'ICAO': 'origin'}).drop(columns={'IATA'})\n",
    "df_s = df_s.merge(df_airports_iata_icao[['ICAO', 'IATA']], left_on='ArrAirport', right_on='IATA', how='left').rename(columns={'ICAO': 'destination'}).drop(columns={'IATA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d3c01-44f6-4414-b3f5-cc93fcdc0270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify ariprots missing their ICAO code in the IATA-ICAO file\n",
    "print(df_s[df_s.origin.isnull()][['DepAirport', 'DepAirportName']].drop_duplicates())\n",
    "print(df_s[df_s.destination.isnull()][['ArrAirport', 'ArrAirportName']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265d794-14bd-4107-8b4e-505c72979334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates of airports\n",
    "# Merge with df_s to add lat lon of arrival and departure airports\n",
    "df_s = df_s.merge(df_airports[['icao_id', 'lat', 'lon']], left_on='origin', right_on='icao_id', how='left').drop(columns={'icao_id'}).rename(columns={'lat':'DepLat', 'lon':'DepLon'})\n",
    "df_s = df_s.merge(df_airports[['icao_id', 'lat', 'lon']], left_on='destination', right_on='icao_id', how='left').drop(columns={'icao_id'}).rename(columns={'lat':'ArrLat', 'lon':'ArrLon'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1cc142-9f46-435c-b7a5-8fffb00a7359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates missing\n",
    "print(df_s[df_s.DepLat.isnull()]['origin'].drop_duplicates())\n",
    "print(df_s[df_s.ArrLat.isnull()]['destination'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8bf9a9-be96-42de-8cd5-d0d568193740",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_columns = ['Carrier1', 'Carrier1Name', 'FlightNo1', 'CarrDom1', 'CarrDom1Name', 'DepAirport', 'DepAirportName', 'DepLat', 'DepLon', 'DepTerminal', 'DepCity', 'DepCityName', 'DepState', 'DepStateName', 'DepIATACtry', 'DepIATACtryName', 'DepDOTCtry', 'DepDOTCtryName', 'DepReg', 'DepRegName', 'ArrAirport', 'ArrAirportName', 'ArrLat', 'ArrLon', 'ArrTerminal', 'ArrCity', 'ArrCityName', 'ArrState', 'ArrStateName', 'ArrIATACtry', 'ArrIATACtryName', 'ArrDOTCtry', 'ArrDOTCtryName', 'ArrReg', 'ArrRegName', 'LocalDepTime', 'LocalArrTime', 'LocalArrDay', 'LocalDaysOfOp', 'ArrDaysOfOp', 'Service', 'Seats', 'FstSeats', 'BusSeats', 'EcoSeats', 'EffFrom', 'EffTo', 'LocalDaysOfOp1', 'LocalDaysOfOp2', 'LocalDaysOfOp3', 'LocalDaysOfOp4', 'LocalDaysOfOp5', 'LocalDaysOfOp6', 'LocalDaysOfOp7', 'ElapsedTime', 'FlyingTime', 'GroundTime', 'Stops']\n",
    "mid_columns = ['IntAirports', 'IntCities', 'IntCountries', 'AcftChange', 'AcftChApt1', 'AcftChApt2', 'AcftChApt3', 'GeneralAcft', 'GeneralAcftName', 'SpecificAcft', 'SpecificAcftName', 'SecondAcft', 'ThirdAcft', 'FourthAcft', 'Freightons', 'PassClass', 'FreightClass', 'Routing', 'StatMiles', 'NautMiles', 'Km', 'DistStMiles', 'DistNtMiles', 'DistKM', 'Restrictions', 'ShAirlDes', 'ShrAirlineDesName', 'MultCDes', 'DupMarker', 'DupCar1', 'DupCar2', 'DupCar3', 'DupCar4', 'DupCar5', 'DupCar6', 'DupCar7', 'DupCar8', 'OpCar', 'Comment', 'AcftOwnerCode', 'AcftOwnerCodeName', 'CockpitCrewCode', 'CockpitCrewCodeName', 'CabinCrewCode', 'CabinCrewCodeName', 'LongLeg', 'MaxTakeOffWeight', 'HoldVolume', 'RangeKm', 'RangeStatMiles', 'RangeNautMiles', 'CruiseSpeed', 'Category', 'Manufacturer', 'Ghost']\n",
    "final_columns = ['SubGovnApp', 'FltDup', 'Frequency', 'ASMs', 'ASKs', 'TotalSeatCapacity', 'TotalTonnage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f410b-06c3-414f-9c7f-010c4fdce5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_s[first_columns].loc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b344a-4805-48eb-9c04-a264258b1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_s_es[mid_columns].loc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d19a0e-3b97-43e4-bdc4-054a592e9ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_s_es[final_columns].loc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97335937-5a79-4bf5-bbc3-07cdd51f9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move dates to UTC from local\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "from timezonefinder import TimezoneFinder\n",
    "\n",
    "# Initialize TimezoneFinder\n",
    "tf = TimezoneFinder()\n",
    "\n",
    "# Function to convert local times to UTC\n",
    "def convert_to_utc(row, reference_date):\n",
    "    # Define the departure time zones\n",
    "    dep_airport = row['DepAirport']\n",
    "    dep_state = row['DepState']\n",
    "\n",
    "    # Adjust reference date if arrival is next day and not in Europe\n",
    "    # Move date to -1 so that when it arrives to Europe it is in the\n",
    "    # reference date\n",
    "    dep_date = datetime.strptime(reference_date, '%Y-%m-%d')\n",
    "    if row['LocalArrDay'] == 1 and row['DepReg'] != 'EU1' and row['DepReg'] != 'EU2':\n",
    "        dep_date -= timedelta(days=1)\n",
    "\n",
    "    # Get the timezone of the departure airport, either by its coordinates\n",
    "    # or if coordinates not available then by the country of the airport\n",
    "    # note that country might not be good enough (e.g. ES has Canary Islands in a different \n",
    "    # time zone or the US has many different timezones)\n",
    "    if not pd.isna(row['DepLat']):\n",
    "        dep_tz_str = tf.timezone_at(lng=row['DepLon'], lat=row['DepLat'])\n",
    "    else:\n",
    "        # From all the time zones in the country, keep the first one\n",
    "        dep_tz_str = pytz.country_timezones[row['DepIATACtry']][0]\n",
    "    \n",
    "    dep_tz = pytz.timezone(dep_tz_str)\n",
    "        \n",
    "    \n",
    "    # Parse the local departure time\n",
    "    local_dep_time_str = f\"{dep_date.strftime('%Y-%m-%d')} {str(row['LocalDepTime']).zfill(4)[:2]}:{str(row['LocalDepTime']).zfill(4)[2:]}:00\"\n",
    "    local_dep_time = datetime.strptime(local_dep_time_str, '%Y-%m-%d %H:%M:%S')    \n",
    "    local_dep_time = dep_tz.localize(local_dep_time)\n",
    "    \n",
    "    # Convert local departure time to UTC\n",
    "    utc_dep_time = local_dep_time.astimezone(pytz.utc)\n",
    "    \n",
    "    # Calculate the arrival time based on elapsed time\n",
    "    elapsed_time_str = str(row['ElapsedTime']).zfill(4)\n",
    "    elapsed_hours = int(elapsed_time_str[:2])\n",
    "    elapsed_minutes = int(elapsed_time_str[2:])\n",
    "    elapsed_time = timedelta(hours=elapsed_hours, minutes=elapsed_minutes)\n",
    "\n",
    "    local_arr_time = local_dep_time + elapsed_time\n",
    "\n",
    "    # Get the timezone of the arrival airport, either by its coordinates\n",
    "    if not pd.isna(row['ArrLat']):\n",
    "        arr_tz_str = tf.timezone_at(lng=row['ArrLon'], lat=row['ArrLat'])\n",
    "    else:\n",
    "        arr_tz_str = pytz.country_timezones[row['ArrIATACtry']][0]\n",
    "\n",
    "    arr_tz = pytz.timezone(arr_tz_str)\n",
    "\n",
    "    # Convert local arrival time to the correct local timezone\n",
    "    local_arr_time = local_arr_time.astimezone(arr_tz)\n",
    "    \n",
    "    # Convert local arrival time to UTC\n",
    "    utc_arr_time = local_arr_time.astimezone(pytz.utc)\n",
    "    \n",
    "    \n",
    "    # Convert local arrival time to UTC\n",
    "    #utc_arr_time = local_arr_time.astimezone(pytz.utc)\n",
    "    \n",
    "    return pd.Series([utc_dep_time, utc_arr_time, local_dep_time, local_arr_time])\n",
    "\n",
    "\n",
    "\n",
    "reference_utc_date = '2019-09-06'\n",
    "# Apply the function to the DataFrame\n",
    "df_s[['UTC_Departure', 'UTC_Arrival', 'Local_Departure', 'Local_Arrival']] = df_s.apply(convert_to_utc, reference_date=reference_utc_date, axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc92cd0-eb65-4aff-8e40-b239c201fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter flights operating on day of interest\n",
    "\n",
    "# Function to extract day of the week\n",
    "def get_day_of_week(local_departure):\n",
    "    return local_departure.weekday() + 1  # Python's weekday() returns 0 for Monday, so add 1 to match required format\n",
    "\n",
    "# Function to check if flight operates on the day of the week\n",
    "def operates_on_day(row):\n",
    "    return str(row['DayOfWeek']) in row['LocalDaysOfOp']\n",
    "\n",
    "# Function to check if departure date is within the effective date range\n",
    "def within_effective_date_range(row):\n",
    "    dep_date = row['Local_Departure'].date()\n",
    "    eff_from_date = row['EffFrom'].date()\n",
    "    eff_to_date = row['EffTo'].date()\n",
    "    return eff_from_date <= dep_date <= eff_to_date\n",
    "\n",
    "# Add the DayOfWeek column\n",
    "df_s['DayOfWeek'] = df_s['Local_Departure'].apply(get_day_of_week)\n",
    "\n",
    "# Convert EffFrom and EffTo to datetime\n",
    "df_s['EffFrom'] = pd.to_datetime(df_s['EffFrom'], format='%d/%m/%Y')\n",
    "df_s['EffTo'] = pd.to_datetime(df_s['EffTo'], format='%d/%m/%Y')\n",
    "\n",
    "# Filter the DataFrame\n",
    "df_fs_filtered = df_s[df_s.apply(operates_on_day, axis=1)]\n",
    "df_fs_filtered = df_fs_filtered[df_fs_filtered.apply(within_effective_date_range, axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c71ccad-8384-47dc-8f9e-4ce99b1a1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove flights with stops\n",
    "# In original data you can have A - B - C that will appear as three flights:\n",
    "# - A - B - C (With Stops==1)\n",
    "# - A - B\n",
    "# - B - C\n",
    "# Remove the one with stops and keep the 'simple' ones.\n",
    "df_fs_filtered = df_fs_filtered[df_fs_filtered.Stops==0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9bd53-46c3-4bd9-bdd0-807be3540d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_fs_filtered[df_fs_filtered['DepAirport']=='MAD']))\n",
    "print(len(df_fs_filtered[df_fs_filtered['DepAirport']=='BCN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14122afa-5c2f-4c26-9d92-b111b8c8a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have filtered by date of interest, we need to check still codeshares which are not always.\n",
    "# For exmample between LEPA and LEBL there's a flight by Vueling and Iberia which overlaps on some days, in that case\n",
    "# the flight is Iberia, on the other days, it's Vueling, for example.\n",
    "\n",
    "# Function to filter flights\n",
    "def filter_flights(group):\n",
    "    # Create the full flight code\n",
    "    group['FlightCode'] = group['Carrier1'] + ' ' + group['FlightNo1'].astype(str)\n",
    "    \n",
    "    # If the group has only one flight, keep it\n",
    "    if len(group) == 1:\n",
    "        return group\n",
    "    else:\n",
    "        # Print group information before filtering\n",
    "        #print(f\"\\nGroup before filtering (DepAirport: {group['DepAirport'].iloc[0]}, ArrAirport: {group['ArrAirport'].iloc[0]}, LocalDepTime: {group['LocalDepTime'].iloc[0]}, LocalArrTime: {group['LocalArrTime'].iloc[0]}):\")\n",
    "        #print(group[['DepAirport', 'ArrAirport', 'LocalDepTime', 'Carrier1', 'FlightNo1', 'FlightCode', 'OpCar']])\n",
    "        \n",
    "        # Check if a flight code appears in another flight's DupCarx columns\n",
    "        codes_to_remove = set()\n",
    "        flight_codes = set(group['FlightCode'])\n",
    "        mutual_dups = []\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            for i in range(1, 9):\n",
    "                dup_car = row[f'DupCar{i}']\n",
    "                if dup_car in flight_codes:\n",
    "                    if dup_car in group['FlightCode'].values and row['FlightCode'] in group.loc[group['FlightCode'] == dup_car, [f'DupCar{j}' for j in range(1, 9)]].values:\n",
    "                        mutual_dups.append((row['FlightCode'], dup_car))\n",
    "                    else:\n",
    "                        codes_to_remove.add(dup_car)\n",
    "\n",
    "        # Handle mutual duplicates\n",
    "        for fc1, fc2 in mutual_dups:\n",
    "            fc1_op = group.loc[group['FlightCode'] == fc1, 'OpCar'].values[0]\n",
    "            fc2_op = group.loc[group['FlightCode'] == fc2, 'OpCar'].values[0]\n",
    "            if fc1_op == 'O':\n",
    "                codes_to_remove.add(fc2)\n",
    "            elif fc2_op == 'O':\n",
    "                codes_to_remove.add(fc1)\n",
    "        \n",
    "        # Keep flights whose code is not in the codes_to_remove set\n",
    "        filtered_group = group[~group['FlightCode'].isin(codes_to_remove)]\n",
    "        \n",
    "        # Print group information after filtering\n",
    "        #print(f\"\\nGroup after filtering (DepAirport: {filtered_group['DepAirport'].iloc[0]}, ArrAirport: {filtered_group['ArrAirport'].iloc[0]}, LocalDepTime: {filtered_group['LocalDepTime'].iloc[0]}, LocalArrTime: {filtered_group['LocalArrTime'].iloc[0]}):\")\n",
    "        #print(filtered_group[['DepAirport', 'ArrAirport', 'LocalDepTime', 'Carrier1', 'FlightNo1', 'FlightCode']])\n",
    "        #print(\"----\")\n",
    "        \n",
    "        # Keep flights whose code is not in the codes_to_remove set\n",
    "        return filtered_group\n",
    "\n",
    "\n",
    "# Group by the four columns\n",
    "grouped = df_fs_filtered.groupby(['DepAirport', 'ArrAirport', 'LocalDepTime', 'LocalArrTime'])\n",
    "\n",
    "\n",
    "print(len(df_fs_filtered))\n",
    "\n",
    "# Apply the filter function to each group\n",
    "df_filtered = grouped.apply(filter_flights).reset_index(drop=True)\n",
    "\n",
    "print(len(df_filtered))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ce181-e518-44d5-9ea0-40144926a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_fs_filtered[df_fs_filtered['DepAirport']=='MAD']))\n",
    "print(len(df_fs_filtered[df_fs_filtered['DepAirport']=='BCN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20248d7-2011-41d1-b34a-c26e9da3a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print duplicates flights still remaining. It could be legit (two airlines with same o-d at same times...)\n",
    "# Group by the four columns\n",
    "grouped = df_filtered.groupby(['DepAirport', 'ArrAirport', 'LocalDepTime', 'LocalArrTime'])\n",
    "\n",
    "# Filter groups with more than one entry\n",
    "post_filtered_df = grouped.filter(lambda x: len(x) > 1)\n",
    "\n",
    "# Print the groups with more than one flight\n",
    "for name, group in post_filtered_df.groupby(['DepAirport', 'ArrAirport', 'LocalDepTime', 'LocalArrTime']):\n",
    "    print(f\"DepAirport: {name[0]}, ArrAirport: {name[1]}, LocalDepTime: {name[2]}, LocalArrTime: {name[3]}\")\n",
    "    print(group[['DepAirport', 'ArrAirport', 'LocalDepTime', 'Carrier1', 'FlightNo1', 'OpCar', 'DupCar1']])\n",
    "    print(f\"Number of flights in this group: {len(group)}\\n\")\n",
    "\n",
    "# Keep the rows that are the only ones in their group\n",
    "unique_df = grouped.filter(lambda x: len(x) == 1)\n",
    "\n",
    "# Combine the unique and non-unique groups\n",
    "#final_df = pd.concat([unique_df, filtered_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e530d-6093-42c9-ac30-177820bdc7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the schedules\n",
    "df_filtered = df_filtered[['service_id', 'origin', 'destination',\n",
    "                                 'DepTerminal', 'ArrTerminal',\n",
    "                                 'UTC_Departure', 'UTC_Arrival', \n",
    "                                 'Local_Departure', 'Local_Arrival',\n",
    "                                 'Carrier1', 'SpecificAcft', 'Seats', 'DistKM']].copy()\n",
    "\n",
    "df_filtered = df_filtered.rename(columns={'DepTerminal': 'dep_terminal',\n",
    "                               'ArrTerminal': 'arr_terminal',\n",
    "                               'UTC_Departure':'sobt',\n",
    "                               'UTC_Arrival':'sibt',\n",
    "                               'Local_Departure': 'sobt_local',\n",
    "                               'Local_Arrival': 'sibt_local',\n",
    "                               'Carrier1':'provider',\n",
    "                               'SpecificAcft':'act_type',\n",
    "                               'Seats': 'seats',\n",
    "                               'DistKM':'gcdistance'})#to_csv('../data/oag_schedules/schedules_test.csv', index=False)#, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract the offset in hours and minutes\n",
    "def extract_offset(x):\n",
    "    x = str(x)\n",
    "    if len(x.split(\"+\")) > 1:\n",
    "        return \"+\"+x.split(\"+\")[-1]\n",
    "    else:\n",
    "        return \"-\"+x.split(\"-\")[-1]\n",
    "    \n",
    "    \n",
    "# Extract timezone information\n",
    "df_filtered['sobt_tz'] = df_filtered['sobt'].apply(lambda x: extract_offset(x))\n",
    "df_filtered['sobt_local_tz'] = df_filtered['sobt_local'].apply(lambda x: extract_offset(x))\n",
    "df_filtered['sibt_tz'] = df_filtered['sibt'].apply(lambda x: extract_offset(x))\n",
    "df_filtered['sibt_local_tz'] = df_filtered['sibt_local'].apply(lambda x: extract_offset(x))\n",
    "\n",
    "# Remove timezone information from datetime columns\n",
    "df_filtered['sobt'] = df_filtered['sobt'].dt.tz_localize(None)\n",
    "df_filtered['sobt_local'] = df_filtered['sobt_local'].apply(lambda x: x.replace(tzinfo=None))\n",
    "df_filtered['sibt'] = df_filtered['sibt'].dt.tz_localize(None)\n",
    "df_filtered['sibt_local'] = df_filtered['sibt_local'].apply(lambda x: x.replace(tzinfo=None))\n",
    "\n",
    "# Remove flights which are same airline and all the same but the flight service\n",
    "df_filtered = df_filtered.drop_duplicates(subset=[col for col in df_filtered.columns if col !='service_id'], keep='first')\n",
    "\n",
    "print(len(df_filtered))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982058c8-a374-4398-84e6-c800901ff18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print again duplicates flights still remaining. It could be legit (two airlines with same o-d at same times...)\n",
    "# Group by the four columns\n",
    "grouped = df_filtered.groupby(['origin', 'destination', 'sobt', 'sibt'])\n",
    "\n",
    "# Filter groups with more than one entry\n",
    "post_filtered_df = grouped.filter(lambda x: len(x) > 1)\n",
    "\n",
    "n_dup = 0\n",
    "# Print the groups with more than one flight\n",
    "for name, group in post_filtered_df.groupby(['origin', 'destination', 'sobt', 'sibt']):\n",
    "    n_dup += 1\n",
    "    print(f\"DepAirport: {name[0]}, ArrAirport: {name[1]}, LocalDepTime: {name[2]}, LocalArrTime: {name[3]}\")\n",
    "    print(group[['origin', 'destination', 'sobt', 'provider', 'act_type']])\n",
    "    print(f\"Number of flights in this group: {len(group)}\\n\")\n",
    "\n",
    "print(f\"Total number of groups: {n_dup}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124dcc1-a9b8-417c-a101-2e2b35f660a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify seats of act_type that are missing their seats\n",
    "if len(df_filtered[df_filtered.seats==0].act_type.drop_duplicates())>0:\n",
    "    pd_seats_missing = pd.read_csv('./seats_ac_missing.csv')\n",
    "\n",
    "dict_ac_seats = pd_seats_missing.set_index('ac_type').to_dict()['seats']\n",
    "\n",
    "df_filtered['seats'] = df_filtered.apply(lambda x: dict_ac_seats.get(x['act_type'], x['seats']), axis=1)\n",
    "\n",
    "df_filtered[df_filtered.seats==0].act_type.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49811448-ad1e-420e-8156-4a111b14a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[['service_id', 'origin', 'destination', 'dep_terminal', 'arr_terminal',\n",
    "    'sobt', 'sibt', 'sobt_tz', 'sibt_tz', \n",
    "    'sobt_local', 'sibt_local','sobt_local_tz', 'sibt_local_tz',\n",
    "    'provider', 'act_type',\n",
    "    'seats', 'gcdistance']].to_csv(f_schedules_output, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa474fd4-7fc7-4db2-bf9b-00239a52ec8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f78d7f2-87c4-4c08-9be5-5ff439e2523f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86657c09-f77a-419a-be62-7f83bcaf7733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be26400-673d-48c5-a809-9604b5594c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_filtered))\n",
    "len(df_filtered.drop_duplicates(subset=[col for col in df_filtered.columns if col !='service_id'], keep='first'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b235cae2-73bc-4c5f-bb17-d3256caca6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[((df_filtered.provider=='QR') | (df_filtered.provider=='VY') | (df_filtered.provider=='IB')) & \n",
    "(df_filtered.origin=='LEPA') & ((df_filtered.destination=='LEBL'))].sort_values('sobt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043214d-af05-41eb-bf0c-cb40335ed880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[(df_filtered.origin=='EDDL') & (df_filtered.destination=='LEPA')].sort_values('sobt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a645793-4a8c-4dfe-abb3-18c17c449418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ddb792-e9a0-475e-9731-085d5817fe0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mercury-mmx",
   "language": "python",
   "name": "mercury-mmx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
